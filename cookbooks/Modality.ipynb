{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a40e499-baa2-4405-970a-4b23ecedfb1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Upsample_Anything'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m to_pil_image\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mUpsample_Anything\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mupsample_anything\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m UPA\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mutils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m visualize_pca_one\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mPIL\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Upsample_Anything'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Upsample_Anything.upsample_anything import UPA\n",
    "from utils import visualize_pca_one\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def fit_pca_basis(feature_4d):\n",
    "    \"\"\"\n",
    "    feature_4d: [1, C, H, W]\n",
    "    Return PCA model\n",
    "    \"\"\"\n",
    "    feat = feature_4d[0].detach().cpu().numpy()   # [C,H,W]\n",
    "    C, H, W = feat.shape\n",
    "    X = feat.reshape(C, -1).T                    # [HW, C]\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(X)\n",
    "    return pca\n",
    "\n",
    "\n",
    "def apply_pca(feature_4d, pca, gamma=1/1.8, brightness=1.2):\n",
    "    \"\"\"\n",
    "    feature_4d: [1,C,H,W]\n",
    "    return: brightened PCA RGB image\n",
    "    \"\"\"\n",
    "    feat = feature_4d[0].detach().cpu().numpy()   # [C,H,W]\n",
    "    C, H, W = feat.shape\n",
    "\n",
    "    X = feat.reshape(C, -1).T                     # [HW, C]\n",
    "    X_pca = pca.transform(X)                      # [HW,3]\n",
    "\n",
    "    # Normalize 0~1\n",
    "    X_pca = (X_pca - X_pca.min()) / (X_pca.max() - X_pca.min() + 1e-6)\n",
    "\n",
    "    X_pca = np.power(X_pca, gamma)\n",
    "\n",
    "    X_pca = X_pca * brightness\n",
    "    X_pca = np.clip(X_pca, 0, 1)\n",
    "\n",
    "    X_pca = X_pca.reshape(H, W, 3)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "\n",
    "def visualize_all(img, guided_modality, lr_feature, hr_rgb, hr_depth):\n",
    "    \"\"\"\n",
    "    Show: RGB / Depth / LR PCA / HR_RGB PCA / HR_Depth PCA\n",
    "    \"\"\"\n",
    "    pca = fit_pca_basis(lr_feature)\n",
    "\n",
    "    lr_pca  = apply_pca(lr_feature, pca)\n",
    "    rgb_pca = apply_pca(hr_rgb, pca)\n",
    "    dep_pca = apply_pca(hr_depth, pca)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "\n",
    "    # 1. Original RGB\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"RGB\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # 2. Guided Modality (Depth)\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(guided_modality)\n",
    "    plt.title(\"Guided Modality (Depth)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # 3. LR Feature PCA\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(lr_pca)\n",
    "    plt.title(\"LR Feature (PCA)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # 4. HR (RGB guided)\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(rgb_pca)\n",
    "    plt.title(\"HR Feature (RGB Guided)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # 5. HR (Depth guided)\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(dep_pca)\n",
    "    plt.title(\"HR Feature (Depth Guided)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return lr_pca, rgb_pca, dep_pca\n",
    "\n",
    "\n",
    "\n",
    "def dinov2_infer(img):\n",
    "    dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device).eval()\n",
    "\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))\n",
    "    ])\n",
    "    img_t = transform(img).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            feats_list = dinov2_vits14.get_intermediate_layers(img_t, n=1)\n",
    "            feats_all = feats_list[0].squeeze(0)\n",
    "\n",
    "    H=W=int(feats_all.shape[0]**0.5)\n",
    "    feat_map=feats_all.reshape(H,W,-1).permute(2,0,1).unsqueeze(0)\n",
    "\n",
    "    return feat_map\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img_path = \"img/airplane2.jpg\"\n",
    "    img = Image.open(img_path).convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "    depth_path = \"img/airplane2_depth.jpg\"\n",
    "    guided_modality = Image.open(depth_path).convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "    # Extract LR feature\n",
    "    lr_feature = dinov2_infer(img)\n",
    "\n",
    "    # Upsample\n",
    "    hr_rgb   = UPA(img, lr_feature)\n",
    "    hr_depth = UPA(guided_modality, lr_feature)\n",
    "\n",
    "    # ===>>> Jupyter Visualization <<<===\n",
    "    visualize_all(img, guided_modality, lr_feature, hr_rgb, hr_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e8600-1153-494d-a7d0-66e0e61ffa29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1af496-fafe-4991-9544-8341ce9f5f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
